{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# Send test prompts to multiple models for evaluation\n\n### Scenario\nYou are choosing a large language model for your project.  You have narrowed down the list of potential models based on reading about the available models.  Now, you want to send test prompts to multiple \n\nNotebook sections:\n- [Step 1: Set up IBM watsonx.ai foundation model Python library prerequisites](#step1)\n- [Step 2: Create a function for prompting a model](#step2)\n- [Step 3: Create a simple function for prompting multiple models](#step3)\n- [Step 4: Create a function for sending multiple prompts to multiple models](#step4)\n- [Step 5: Create a function with model-specific prompt parameter overrides](#step5)\n- [Step 6: Create a function with model-specific prompt text overrides](#step6)\n\nBy the end of this notebook, you'll have test results to help you decide which model to use for your project at this time:\n\n<img src=\"https://raw.githubusercontent.com/spackows/watsonx.ai-samples/main/sample-02_prompt-multiple-models/images/sample-02_prompt-multiple-models.png\" width=\"70%\" title=\"Image of DataFrame\" />", "metadata": {}}, {"cell_type": "code", "source": "", "metadata": {"id": "b1445476-6483-49f4-a733-efc4815e27a4"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "f1a8e433-ccce-4142-ba2e-45014afbbe8f"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "<a id=\"step1\"></a>\n## Step 1: Set up IBM watsonx.ai foundation model Python library prerequisites\nBefore you can prompt a foundation model in watsonx.ai, you must perform the following setup tasks:\n- 1.1 Create an instance of the Watson Machine Learning service\n- 1.2 Associate the Watson Machine Learning instance with the current project\n- 1.3 Create an IBM Cloud API key\n- 1.4 Create a credentials dictionary for Watson Machine learning\n- 1.5 Look up the current project ID", "metadata": {}}, {"cell_type": "markdown", "source": "### 1.1 Create an instance of the Watson Machine Learning service\nIf you don't already have an instance of the IBM Watson Machine Learning service, you can create an instance of the service from the IBM Cloud catalog: <a href=\"https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/\" target=\"_blank\">Watson Machine Learning service</a>", "metadata": {}}, {"cell_type": "markdown", "source": "### 1.2 Associate an instance of the Watson Machine Learning service with the current project\nThe _current project_ is the project in which you are running this notebook.\n\nIf an instance of Watson Machine Learning is not already associated with the current project, follow the instructions in this topic to do so: <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/assoc-services.html?context=wx&audience=wdp\" target=\"_blank\">Adding associated services to a project</a>", "metadata": {}}, {"cell_type": "markdown", "source": "### 1.3 Create an IBM Cloud API key\nCreate an IBM Cloud API key by following these instruction: <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui#create_user_key\" target=\"_blank\">Creating an IBM Cloud API key</a>\n\nThen paste your new IBM Cloud API key in the code cell below.", "metadata": {}}, {"cell_type": "code", "source": "g_cloud_apikey = \"\"", "metadata": {"id": "27d4a2cb-a661-4ded-9442-b590d78b0540"}, "outputs": [], "execution_count": 1}, {"cell_type": "markdown", "source": "### 1.4 Create a credentials dictionary for Watson Machine learning\nSee: [Authentication](https://ibm.github.io/watson-machine-learning-sdk/setup_cloud.html#authentication)", "metadata": {}}, {"cell_type": "code", "source": "g_wml_credentials = { \n    \"url\"    : \"https://us-south.ml.cloud.ibm.com\", \n    \"apikey\" : g_cloud_apikey\n}", "metadata": {"id": "ac6e6728-4397-476d-9ed0-18229be73bcc"}, "outputs": [], "execution_count": 2}, {"cell_type": "markdown", "source": "### 1.5 Look up the current project ID\nThe _current project_ is the project in which you are running this notebook.  You can get the ID of the current project programmatically by running the following cell.", "metadata": {}}, {"cell_type": "code", "source": "import os\n\ng_project_id = os.environ[\"PROJECT_ID\"]", "metadata": {"id": "94852b00-c147-4156-b371-ebdd2c3e0a4a"}, "outputs": [], "execution_count": 3}, {"cell_type": "code", "source": "", "metadata": {"id": "35039066-2614-45c2-b8a8-d468720a4478"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "dbdf5b01-b4ab-4bb6-a420-097cf5ec5be2"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "<a id=\"step2\"></a>\n## Step 2: Create a function for prompting a model\n\nSee: [Foundation models Python library](https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html)", "metadata": {}}, {"cell_type": "code", "source": "from ibm_watson_machine_learning.foundation_models import Model\nimport json\n\ndef generate( model_id, prompt_parameters, prompt_text, b_debug=False ):\n    model = Model( model_id, g_wml_credentials, prompt_parameters, g_project_id )\n    raw_response = model.generate( prompt_text )\n    if b_debug:\n        print( \"prompt_text:\\n'\" + prompt_text + \"'\\n\" )\n        print( \"raw_response:\\n\" + json.dumps( raw_response, indent=3 ) )\n    if ( \"results\" in raw_response ) \\\n       and ( len( raw_response[\"results\"] ) > 0 ) \\\n       and ( \"generated_text\" in raw_response[\"results\"][0] ):\n        return raw_response, raw_response[\"results\"][0][\"generated_text\"]\n    else:\n        return raw_response, \"\"", "metadata": {"id": "da1b9c1d-323d-4064-b6cf-c378a026f80e"}, "outputs": [], "execution_count": 4}, {"cell_type": "code", "source": "raw_response, generated_output = generate( \"google/flan-t5-xxl\", {}, \"I took my dog for \", b_debug=True )\n\nprint( \"\\ngenerated_output:\\n\" + generated_output )", "metadata": {"id": "01ca8552-03c5-4be7-af14-332a96b785a2"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "61329473-f9d1-4273-9529-621be361da73"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "512e325e-3f2e-4ec6-900a-f0a7c6e79798"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "<a id=\"step3\"></a>\n## Step 3: Create a simple function for prompting multiple models", "metadata": {}}, {"cell_type": "markdown", "source": "### Use the Python library to list supported models", "metadata": {}}, {"cell_type": "code", "source": "from ibm_watsonx_ai import APIClient\nfrom ibm_watsonx_ai.foundation_models import ModelInference\nimport textwrap\n\ndef listAllModelIDs( client ):\n    model_enums = client.foundation_models.TextModels\n    all_model_ids = [ e.value for e in model_enums ]\n    return all_model_ids\n    \ndef modelDetails( client, model_id ):\n    model = ModelInference( model_id=model_id, project_id=g_project_id, api_client=client)\n    model_details = model.get_details()\n    return model_details\n    \ndef isDeprecatedOrWithdrawn( model_details ):\n    for lifecycle_event in model_details[\"lifecycle\"]:\n        if re.match( r\"deprecated|withdrawn\", lifecycle_event[\"id\"] ):\n            return True\n    return False\n\ndef detailsSubset( model_details ):\n    return { \"Provider / Source\" : model_details[\"provider\"] + \"\\n\\n\" + model_details[\"source\"],\n             \"Model ID\" : model_details[\"model_id\"],\n             \"Description\" : \"\\n\".join( textwrap.wrap( model_details[\"short_description\"], 30 ) ),\n             \"Use cases\" : \"- \" + \"\\n- \".join( sorted( model_details[\"task_ids\"] ) ) }\n\ndef modelsDetails( client, model_ids ):\n    all_model_details = []\n    for model_id in model_ids:\n        model_details = modelDetails( client, model_id )\n        if isDeprecatedOrWithdrawn( model_details ):\n            continue\n        model_details_subset = detailsSubset( model_details )\n        all_model_details.append( model_details_subset )\n    return all_model_details\n\ndef modelDetailsDF():\n    client = APIClient( g_wml_credentials )\n    model_ids = listAllModelIDs( client )\n    models_details = modelsDetails( client, model_ids )\n    models_details_df = pd.DataFrame( models_details )\n    return models_details_df", "metadata": {"id": "23ef69c5-16a5-439a-9b11-acfc05bd5f8e"}, "outputs": [], "execution_count": 36}, {"cell_type": "code", "source": "models_details_df = modelDetailsDF()", "metadata": {"id": "311040e3-4388-4ab3-9679-61a6fa6d690f"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "from tabulate import tabulate\n\nprint( tabulate( models_details_df, headers=\"keys\", tablefmt=\"grid\", showindex=False ) )", "metadata": {"id": "0573f02c-1876-4410-8562-0b1924b7a209"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### [Optional] Filter models by use case", "metadata": {"id": "1b5affe5-087d-429d-865f-2705d4e6161e"}}, {"cell_type": "code", "source": "def listModelsByUseCase( models_details_df, use_cases ):\n    if( len( use_cases ) < 1 ):\n        return list( models_details_df[\"Model ID\"] )\n    regex_str = \"|\".join( [ uc.strip().lower() for uc in use_cases ] )\n    models_subset_df = models_details_df[ models_details_df[\"Use cases\"].str.contains( regex_str, regex= True, na=False) ]\n    return list( models_subset_df[\"Model ID\"] )", "metadata": {"id": "c6f90417-adf5-48ca-a17d-23c9f5da0fde"}, "outputs": [], "execution_count": 81}, {"cell_type": "code", "source": "model_ids = listModelsByUseCase( models_details_df, [ \"generation\" ] )\nmodel_ids", "metadata": {"id": "eb3ee542-06b0-4f0c-a0b1-66a6876f337c"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### Prompt models", "metadata": {"id": "7e559671-f54b-4485-b6a9-48db0a668d65"}}, {"cell_type": "code", "source": "import re\n\ndef promptModels1( prompt_text, model_ids_arr, prompt_parameters={}, b_debug=False ):\n    all_results_arr = []\n    for model_id in model_ids_arr:\n        raw_response, generated_output = generate( model_id, prompt_parameters, prompt_text, b_debug )\n        generated_output = generated_output.strip()\n        if( \"system\" in raw_response ):\n            del( raw_response[\"system\"] )\n        all_results_arr.append( { \"model_id\"         : model_id, \n                                  \"model_short_id\"   : re.sub( r\"^.*\\/\", \"\", model_id ),\n                                  \"prompt_text\"      : prompt_text,\n                                  \"raw_response\"     : raw_response, \n                                  \"generated_output\" : generated_output } )\n    return all_results_arr", "metadata": {"id": "ccf9767f-17d2-43a1-8525-7f719d58c693"}, "outputs": [], "execution_count": 70}, {"cell_type": "code", "source": "prompt_parameters = {\n    \"decoding_method\" : \"greedy\",\n    \"min_new_tokens\"  : 0,\n    \"max_new_tokens\"  : 20\n}", "metadata": {"id": "a9ecb193-9442-4206-952d-342abdbeca8e"}, "outputs": [], "execution_count": 71}, {"cell_type": "code", "source": "prompt_text = \"I took my dog for a \"", "metadata": {"id": "0405e9af-2e7b-4cbe-960a-ccc7221ed5ba"}, "outputs": [], "execution_count": 72}, {"cell_type": "code", "source": "results_arr = promptModels1( prompt_text, model_ids, prompt_parameters )", "metadata": {"id": "f9b62af6-4668-4c6c-b164-d9a74fbe2aad"}, "outputs": [], "execution_count": 73}, {"cell_type": "code", "source": "print( json.dumps( results_arr, indent=3 ) )", "metadata": {"id": "2562f882-6a70-4540-9dfa-fdfc4a3ec423"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### Display results in a DataFrame", "metadata": {}}, {"cell_type": "code", "source": "import pandas as pd\n\ndef styleDataFrame( styler ):\n    styler.set_properties( **{ \"text-align\" : \"left\", \"vertical-align\" : \"top\", \"padding\" : \"10px 20px 10px 20px\", \"font-size\" : \"120%\" } )\n    styler.set_table_styles( [ dict( selector=\"th\", props=\"text-align: center\" ) ] )\n    return styler\n\ndef styleModelIDCol( styler ):\n    f_model_id = lambda v: \"width: 190px; min-width: 190px; max-width: 190px;\"\n    styler.applymap( f_model_id, subset=[ \"model_short_id\" ] )\n    return styler\n\ndef resultsDF1( results_arr ):\n    df_org = pd.DataFrame( results_arr )\n    result_df = df_org[ [ \"model_short_id\", \"generated_output\" ] ]\n    result_df = result_df.sort_values( [ \"model_short_id\" ] ).reset_index( drop=True )\n    result_df = result_df.replace( { \"\\\\n\" : \"<br/>\" }, regex=True )\n    styler = result_df.style.pipe( styleDataFrame )\n    styler = styler.pipe( styleModelIDCol )\n    return styler", "metadata": {"id": "9b0056ee-2d4f-4685-8bf8-a7df0b5ae4a8"}, "outputs": [], "execution_count": 65}, {"cell_type": "code", "source": "df = resultsDF1( results_arr )\n\nprint( \"Prompt text:\\n'\" + prompt_text + \"'\\n\" )\nprint( \"Results:\" )\ndf", "metadata": {"id": "22b714e4-8b86-4331-abd2-aa00d6d738a7"}, "outputs": [{"name": "stdout", "text": "Prompt text:\n'I took my dog for a '\n\nResults:\n", "output_type": "stream"}, {"execution_count": 66, "output_type": "execute_result", "data": {"text/plain": "<pandas.io.formats.style.Styler at 0x7f051617e290>", "text/html": "<style type=\"text/css\">\n#T_9eb2a th {\n  text-align: center;\n}\n#T_9eb2a_row0_col0, #T_9eb2a_row1_col0, #T_9eb2a_row2_col0, #T_9eb2a_row3_col0, #T_9eb2a_row4_col0, #T_9eb2a_row5_col0, #T_9eb2a_row6_col0, #T_9eb2a_row7_col0, #T_9eb2a_row8_col0, #T_9eb2a_row9_col0, #T_9eb2a_row10_col0, #T_9eb2a_row11_col0, #T_9eb2a_row12_col0, #T_9eb2a_row13_col0, #T_9eb2a_row14_col0, #T_9eb2a_row15_col0, #T_9eb2a_row16_col0, #T_9eb2a_row17_col0 {\n  text-align: left;\n  vertical-align: top;\n  padding: 10px 20px 10px 20px;\n  font-size: 120%;\n  width: 190px;\n  min-width: 190px;\n  max-width: 190px;\n}\n#T_9eb2a_row0_col1, #T_9eb2a_row1_col1, #T_9eb2a_row2_col1, #T_9eb2a_row3_col1, #T_9eb2a_row4_col1, #T_9eb2a_row5_col1, #T_9eb2a_row6_col1, #T_9eb2a_row7_col1, #T_9eb2a_row8_col1, #T_9eb2a_row9_col1, #T_9eb2a_row10_col1, #T_9eb2a_row11_col1, #T_9eb2a_row12_col1, #T_9eb2a_row13_col1, #T_9eb2a_row14_col1, #T_9eb2a_row15_col1, #T_9eb2a_row16_col1, #T_9eb2a_row17_col1 {\n  text-align: left;\n  vertical-align: top;\n  padding: 10px 20px 10px 20px;\n  font-size: 120%;\n}\n</style>\n<table id=\"T_9eb2a\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_9eb2a_level0_col0\" class=\"col_heading level0 col0\" >model_short_id</th>\n      <th id=\"T_9eb2a_level0_col1\" class=\"col_heading level0 col1\" >generated_output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_9eb2a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_9eb2a_row0_col0\" class=\"data row0 col0\" >flan-ul2</td>\n      <td id=\"T_9eb2a_row0_col1\" class=\"data row0 col1\" >walk</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_9eb2a_row1_col0\" class=\"data row1 col0\" >granite-13b-instruct-v2</td>\n      <td id=\"T_9eb2a_row1_col1\" class=\"data row1 col1\" >walkI took my dog for a walk.</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_9eb2a_row2_col0\" class=\"data row2 col0\" >granite-20b-code-instruct</td>\n      <td id=\"T_9eb2a_row2_col1\" class=\"data row2 col1\" >ride on his new remote control car. On the first day, I took my dog 20</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_9eb2a_row3_col0\" class=\"data row3 col0\" >granite-3-2-8b-instruct</td>\n      <td id=\"T_9eb2a_row3_col1\" class=\"data row3 col1\" >10-mile hike today. He's a 10-year-old German</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_9eb2a_row4_col0\" class=\"data row4 col0\" >granite-3-2b-instruct</td>\n      <td id=\"T_9eb2a_row4_col1\" class=\"data row4 col1\" >ride in the car. I noticed that the car's interior was quite dusty. I decided to</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_9eb2a_row5_col0\" class=\"data row5 col0\" >granite-3-8b-instruct</td>\n      <td id=\"T_9eb2a_row5_col1\" class=\"data row5 col1\" >10-mile hike today. He's a 10-year-old German</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n      <td id=\"T_9eb2a_row6_col0\" class=\"data row6 col0\" >granite-34b-code-instruct</td>\n      <td id=\"T_9eb2a_row6_col1\" class=\"data row6 col1\" >ride on the Ferris wheel. On the last ride, when my dog was at the</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n      <td id=\"T_9eb2a_row7_col0\" class=\"data row7 col0\" >granite-3b-code-instruct</td>\n      <td id=\"T_9eb2a_row7_col1\" class=\"data row7 col1\" >ride on the way to work today. I was a little worried about him, but he was</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n      <td id=\"T_9eb2a_row8_col0\" class=\"data row8 col0\" >granite-8b-code-instruct</td>\n      <td id=\"T_9eb2a_row8_col1\" class=\"data row8 col1\" >ride on the roller coaster at the park. He was really scared and started to</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n      <td id=\"T_9eb2a_row9_col0\" class=\"data row9 col0\" >llama-3-2-11b-vision-instruct</td>\n      <td id=\"T_9eb2a_row9_col1\" class=\"data row9 col1\" >3 mile walk today. The weather was perfect, sunny and cool. We walked through a beautiful park</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n      <td id=\"T_9eb2a_row10_col0\" class=\"data row10 col0\" >llama-3-2-1b-instruct</td>\n      <td id=\"T_9eb2a_row10_col1\" class=\"data row10 col1\" >30-minute walk around the block. I was looking forward to a relaxing afternoon, but as I was</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n      <td id=\"T_9eb2a_row11_col0\" class=\"data row11 col0\" >llama-3-2-3b-instruct</td>\n      <td id=\"T_9eb2a_row11_col1\" class=\"data row11 col1\" >30-minute walk around the block. We saw a few squirrels, some birds, and a cat</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n      <td id=\"T_9eb2a_row12_col0\" class=\"data row12 col0\" >llama-3-2-90b-vision-instruct</td>\n      <td id=\"T_9eb2a_row12_col1\" class=\"data row12 col1\" >2 mile walk this morning. It was a beautiful day, the sun was shining, and the birds</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n      <td id=\"T_9eb2a_row13_col0\" class=\"data row13 col0\" >llama-3-3-70b-instruct</td>\n      <td id=\"T_9eb2a_row13_col1\" class=\"data row13 col1\" >2 mile walk this morning. It was a beautiful day, and I was feeling good. I was</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n      <td id=\"T_9eb2a_row14_col0\" class=\"data row14 col0\" >llama-3-405b-instruct</td>\n      <td id=\"T_9eb2a_row14_col1\" class=\"data row14 col1\" >2-mile walk this morning. The sun was shining, the birds were singing, and the air was</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n      <td id=\"T_9eb2a_row15_col0\" class=\"data row15 col0\" >llama-guard-3-11b-vision</td>\n      <td id=\"T_9eb2a_row15_col1\" class=\"data row15 col1\" >1safesafesafesafesafesafesafesafesafesafesafesafesafesafesafesafesafesafesafe</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n      <td id=\"T_9eb2a_row16_col0\" class=\"data row16 col0\" >mistral-large</td>\n      <td id=\"T_9eb2a_row16_col1\" class=\"data row16 col1\" >2 mile walk this morning. It was a beautiful morning, and I was feeling good. I was</td>\n    </tr>\n    <tr>\n      <th id=\"T_9eb2a_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n      <td id=\"T_9eb2a_row17_col0\" class=\"data row17 col0\" >mixtral-8x7b-instruct-v01</td>\n      <td id=\"T_9eb2a_row17_col1\" class=\"data row17 col1\" >20 minute walk this morning. I was feeling a little anxious about the day ahead and I knew</td>\n    </tr>\n  </tbody>\n</table>\n"}, "metadata": {}}], "execution_count": 66}, {"cell_type": "code", "source": "", "metadata": {"id": "9218f2f3-0670-48eb-8397-c93d93c23670"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "092278e5-2e3b-4d4b-bd58-c5845e0d283d"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "<a id=\"step4\"></a>\n## Step 4: Create a function for sending multiple prompts to multiple models", "metadata": {}}, {"cell_type": "code", "source": "def promptModels2( prompts_arr, model_ids_arr, prompt_parameters={}, b_debug=False ):\n    all_results_arr = []\n    for i in range( len( prompts_arr ) ):\n        prompt_text = prompts_arr[i]\n        for model_id in model_ids_arr:\n            raw_response, generated_output = generate( model_id, prompt_parameters, prompt_text, b_debug )\n            generated_output = generated_output.strip()\n            if( \"system\" in raw_response ):\n                del( raw_response[\"system\"] )\n            all_results_arr.append( { \"prompt_num\"       : i,\n                                      \"model_id\"         : model_id, \n                                      \"prompt_text\"      : prompt_text,\n                                      \"model_short_id\"   : re.sub( r\"^.*\\/\", \"\", model_id ),\n                                      \"raw_response\"     : raw_response, \n                                      \"generated_output\" : generated_output } )\n    return all_results_arr", "metadata": {"id": "07618e3f-8029-4d02-ab55-86a4064093e7"}, "outputs": [], "execution_count": 75}, {"cell_type": "code", "source": "prompts_arr = [\n    \"I took my dog for a \",\n    \"I took my cat for a \"\n]", "metadata": {"id": "54d76c53-0df4-4a7c-840f-d2c2a00333e1"}, "outputs": [], "execution_count": 76}, {"cell_type": "code", "source": "model_ids = [\n    \"google/flan-t5-xxl\",\n    \"ibm/granite-13b-instruct-v2\",\n    \"meta-llama/llama-3-2-1b-instruct\"\n]", "metadata": {"id": "580b4e21-8314-4677-9e93-d4f3ca93924e"}, "outputs": [], "execution_count": 83}, {"cell_type": "code", "source": "results_arr = promptModels2( prompts_arr, model_ids, prompt_parameters )", "metadata": {"id": "5f1d8a6e-66ef-4248-baaf-acfffeeed305"}, "outputs": [], "execution_count": 84}, {"cell_type": "markdown", "source": "### Make a new display function that includes prompt text", "metadata": {}}, {"cell_type": "code", "source": "g_prompt_col_width = \"200px\"\n\ndef stylePromptCol( styler ):\n    f_prompt = lambda v: \"width: \"     + g_prompt_col_width + \"; \" + \\\n                         \"min-width: \" + g_prompt_col_width + \"; \" + \\\n                         \"max-width: \" + g_prompt_col_width + \";\"\n    styler.applymap( f_prompt, subset=[ \"prompt_text\" ] )\n    return styler\n\ndef resultsDF2( results_arr ):\n    df_org = pd.DataFrame( results_arr )\n    result_df = df_org[ [ \"prompt_num\", \"model_short_id\", \"prompt_text\", \"generated_output\" ] ]\n    result_df = result_df.sort_values( [ \"prompt_num\", \"model_short_id\" ] ).reset_index( drop=True )\n    result_df = result_df.drop( \"prompt_num\", axis=1 )\n    result_df = result_df.replace( { \"\\\\n\" : \"<br/>\" }, regex=True )\n    styler = result_df.style.pipe( styleDataFrame )\n    styler = styler.pipe( styleModelIDCol )\n    styler = styler.pipe( stylePromptCol )\n    return styler", "metadata": {"id": "3ccf397b-2162-4ad9-8b5c-27c2f97c3d20"}, "outputs": [], "execution_count": 85}, {"cell_type": "code", "source": "resultsDF2( results_arr )", "metadata": {"id": "cd441de7-c92e-4523-a5d3-c0e118962a49"}, "outputs": [{"execution_count": 86, "output_type": "execute_result", "data": {"text/plain": "<pandas.io.formats.style.Styler at 0x7f050eda5f10>", "text/html": "<style type=\"text/css\">\n#T_32f7d th {\n  text-align: center;\n}\n#T_32f7d_row0_col0, #T_32f7d_row1_col0, #T_32f7d_row2_col0, #T_32f7d_row3_col0, #T_32f7d_row4_col0, #T_32f7d_row5_col0 {\n  text-align: left;\n  vertical-align: top;\n  padding: 10px 20px 10px 20px;\n  font-size: 120%;\n  width: 190px;\n  min-width: 190px;\n  max-width: 190px;\n}\n#T_32f7d_row0_col1, #T_32f7d_row1_col1, #T_32f7d_row2_col1, #T_32f7d_row3_col1, #T_32f7d_row4_col1, #T_32f7d_row5_col1 {\n  text-align: left;\n  vertical-align: top;\n  padding: 10px 20px 10px 20px;\n  font-size: 120%;\n  width: 200px;\n  min-width: 200px;\n  max-width: 200px;\n}\n#T_32f7d_row0_col2, #T_32f7d_row1_col2, #T_32f7d_row2_col2, #T_32f7d_row3_col2, #T_32f7d_row4_col2, #T_32f7d_row5_col2 {\n  text-align: left;\n  vertical-align: top;\n  padding: 10px 20px 10px 20px;\n  font-size: 120%;\n}\n</style>\n<table id=\"T_32f7d\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_32f7d_level0_col0\" class=\"col_heading level0 col0\" >model_short_id</th>\n      <th id=\"T_32f7d_level0_col1\" class=\"col_heading level0 col1\" >prompt_text</th>\n      <th id=\"T_32f7d_level0_col2\" class=\"col_heading level0 col2\" >generated_output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_32f7d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_32f7d_row0_col0\" class=\"data row0 col0\" >flan-t5-xxl</td>\n      <td id=\"T_32f7d_row0_col1\" class=\"data row0 col1\" >I took my dog for a </td>\n      <td id=\"T_32f7d_row0_col2\" class=\"data row0 col2\" >walk.</td>\n    </tr>\n    <tr>\n      <th id=\"T_32f7d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_32f7d_row1_col0\" class=\"data row1 col0\" >granite-13b-instruct-v2</td>\n      <td id=\"T_32f7d_row1_col1\" class=\"data row1 col1\" >I took my dog for a </td>\n      <td id=\"T_32f7d_row1_col2\" class=\"data row1 col2\" >walkI took my dog for a walk.</td>\n    </tr>\n    <tr>\n      <th id=\"T_32f7d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_32f7d_row2_col0\" class=\"data row2 col0\" >llama-3-2-1b-instruct</td>\n      <td id=\"T_32f7d_row2_col1\" class=\"data row2 col1\" >I took my dog for a </td>\n      <td id=\"T_32f7d_row2_col2\" class=\"data row2 col2\" >30-minute walk around the block. I was looking forward to a relaxing afternoon, but as I was</td>\n    </tr>\n    <tr>\n      <th id=\"T_32f7d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_32f7d_row3_col0\" class=\"data row3 col0\" >flan-t5-xxl</td>\n      <td id=\"T_32f7d_row3_col1\" class=\"data row3 col1\" >I took my cat for a </td>\n      <td id=\"T_32f7d_row3_col2\" class=\"data row3 col2\" >walk.</td>\n    </tr>\n    <tr>\n      <th id=\"T_32f7d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_32f7d_row4_col0\" class=\"data row4 col0\" >granite-13b-instruct-v2</td>\n      <td id=\"T_32f7d_row4_col1\" class=\"data row4 col1\" >I took my cat for a </td>\n      <td id=\"T_32f7d_row4_col2\" class=\"data row4 col2\" >cat scanThe cat scan was negative.</td>\n    </tr>\n    <tr>\n      <th id=\"T_32f7d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_32f7d_row5_col0\" class=\"data row5 col0\" >llama-3-2-1b-instruct</td>\n      <td id=\"T_32f7d_row5_col1\" class=\"data row5 col1\" >I took my cat for a </td>\n      <td id=\"T_32f7d_row5_col2\" class=\"data row5 col2\" >30-minute walk around the block. I was excited to see how much she would enjoy the fresh air</td>\n    </tr>\n  </tbody>\n</table>\n"}, "metadata": {}}], "execution_count": 86}, {"cell_type": "code", "source": "", "metadata": {"id": "e388efc8-b6b0-46ba-b54f-ca153b509332"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "1751f2ab-196b-4817-abdb-93da38bf4c70"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "<a id=\"step5\"></a>\n## Step 5: Create a function with model-specific parameter overrides", "metadata": {}}, {"cell_type": "code", "source": "def promptModels3( prompts_arr, models_json, prompt_parameters={}, b_debug=False ):\n    all_results_arr = []\n    for i in range( len( prompts_arr ) ):\n        prompt_text = prompts_arr[i]\n        for model_id in models_json.keys():\n            model = models_json[ model_id ]\n            if( \"parameter_overrides\" in model ):\n                for parameter_name in model[\"parameter_overrides\"].keys():\n                    prompt_parameters[ parameter_name ] = model[\"parameter_overrides\"][ parameter_name ]\n            raw_response, generated_output = generate( model_id, prompt_parameters, prompt_text, b_debug )\n            generated_output = generated_output.strip()\n            if( \"system\" in raw_response ):\n                del( raw_response[\"system\"] )\n            all_results_arr.append( { \"prompt_num\"       : i,\n                                      \"model_id\"         : model_id, \n                                      \"model_short_id\"   : re.sub( r\"^.*\\/\", \"\", model_id ),\n                                      \"prompt_text\"      : prompt_text,\n                                      \"raw_response\"     : raw_response, \n                                      \"generated_output\" : generated_output } )\n    return all_results_arr", "metadata": {"id": "7944dc68-88a8-4b48-83e3-196e934f9ff6"}, "outputs": [], "execution_count": 89}, {"cell_type": "code", "source": "models_json = {\n    \"google/flan-t5-xxl\" : {},\n    \"ibm/granite-13b-instruct-v2\"      : { \"parameter_overrides\" : { \"max_new_tokens\" : 60 } },\n    \"meta-llama/llama-3-2-1b-instruct\" : { \"parameter_overrides\" : { \"max_new_tokens\" : 80, \"stop_sequences\" : [ \"\\n\" ] } }\n}", "metadata": {"id": "3f800cbf-1aa3-4336-969b-d4c6ca14d018"}, "outputs": [], "execution_count": 87}, {"cell_type": "code", "source": "results_arr = promptModels3( prompts_arr, models_json, prompt_parameters )", "metadata": {"id": "d8151f3e-8fe9-4d9f-949c-00892f0ac795"}, "outputs": [], "execution_count": 90}, {"cell_type": "code", "source": "resultsDF2( results_arr )", "metadata": {"id": "1b278bd2-3883-4e6b-aa61-d7c5210873eb"}, "outputs": [{"execution_count": 91, "output_type": "execute_result", "data": {"text/plain": "<pandas.io.formats.style.Styler at 0x7f050ed56810>", "text/html": "<style type=\"text/css\">\n#T_44143 th {\n  text-align: center;\n}\n#T_44143_row0_col0, #T_44143_row1_col0, #T_44143_row2_col0, #T_44143_row3_col0, #T_44143_row4_col0, #T_44143_row5_col0 {\n  text-align: left;\n  vertical-align: top;\n  padding: 10px 20px 10px 20px;\n  font-size: 120%;\n  width: 190px;\n  min-width: 190px;\n  max-width: 190px;\n}\n#T_44143_row0_col1, #T_44143_row1_col1, #T_44143_row2_col1, #T_44143_row3_col1, #T_44143_row4_col1, #T_44143_row5_col1 {\n  text-align: left;\n  vertical-align: top;\n  padding: 10px 20px 10px 20px;\n  font-size: 120%;\n  width: 200px;\n  min-width: 200px;\n  max-width: 200px;\n}\n#T_44143_row0_col2, #T_44143_row1_col2, #T_44143_row2_col2, #T_44143_row3_col2, #T_44143_row4_col2, #T_44143_row5_col2 {\n  text-align: left;\n  vertical-align: top;\n  padding: 10px 20px 10px 20px;\n  font-size: 120%;\n}\n</style>\n<table id=\"T_44143\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_44143_level0_col0\" class=\"col_heading level0 col0\" >model_short_id</th>\n      <th id=\"T_44143_level0_col1\" class=\"col_heading level0 col1\" >prompt_text</th>\n      <th id=\"T_44143_level0_col2\" class=\"col_heading level0 col2\" >generated_output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_44143_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_44143_row0_col0\" class=\"data row0 col0\" >flan-t5-xxl</td>\n      <td id=\"T_44143_row0_col1\" class=\"data row0 col1\" >I took my dog for a </td>\n      <td id=\"T_44143_row0_col2\" class=\"data row0 col2\" >walk.</td>\n    </tr>\n    <tr>\n      <th id=\"T_44143_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_44143_row1_col0\" class=\"data row1 col0\" >granite-13b-instruct-v2</td>\n      <td id=\"T_44143_row1_col1\" class=\"data row1 col1\" >I took my dog for a </td>\n      <td id=\"T_44143_row1_col2\" class=\"data row1 col2\" >walkI took my dog for a walk.</td>\n    </tr>\n    <tr>\n      <th id=\"T_44143_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_44143_row2_col0\" class=\"data row2 col0\" >llama-3-2-1b-instruct</td>\n      <td id=\"T_44143_row2_col1\" class=\"data row2 col1\" >I took my dog for a </td>\n      <td id=\"T_44143_row2_col2\" class=\"data row2 col2\" >30-minute walk around the block. I was looking forward to a relaxing afternoon, but as I was walking, I noticed that my dog was acting strangely. He was panting heavily and seemed to be getting more and more agitated by the minute.</td>\n    </tr>\n    <tr>\n      <th id=\"T_44143_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_44143_row3_col0\" class=\"data row3 col0\" >flan-t5-xxl</td>\n      <td id=\"T_44143_row3_col1\" class=\"data row3 col1\" >I took my cat for a </td>\n      <td id=\"T_44143_row3_col2\" class=\"data row3 col2\" >walk.</td>\n    </tr>\n    <tr>\n      <th id=\"T_44143_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_44143_row4_col0\" class=\"data row4 col0\" >granite-13b-instruct-v2</td>\n      <td id=\"T_44143_row4_col1\" class=\"data row4 col1\" >I took my cat for a </td>\n      <td id=\"T_44143_row4_col2\" class=\"data row4 col2\" >cat scanThe cat scan was negative.</td>\n    </tr>\n    <tr>\n      <th id=\"T_44143_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_44143_row5_col0\" class=\"data row5 col0\" >llama-3-2-1b-instruct</td>\n      <td id=\"T_44143_row5_col1\" class=\"data row5 col1\" >I took my cat for a </td>\n      <td id=\"T_44143_row5_col2\" class=\"data row5 col2\" >30-minute walk around the block. I was excited to see how much she would enjoy the fresh air and exercise. As we strolled, I noticed that she was sniffing around a few bushes and then suddenly darted off towards a nearby alleyway.</td>\n    </tr>\n  </tbody>\n</table>\n"}, "metadata": {}}], "execution_count": 91}, {"cell_type": "code", "source": "", "metadata": {"id": "7c9d6c4e-ed34-42f5-a529-6959bfa379d4"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "6c98852a-758f-4fd6-b01e-63fa81ecfbb3"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "<a id=\"step6\"></a>\n## Step 6: Create a function with model-specific prompt overrides", "metadata": {}}, {"cell_type": "code", "source": "def promptModels4( prompts_arr, models_json, prompt_parameters={}, b_debug=False ):\n    all_results_arr = []\n    for i in range( len( prompts_arr ) ):\n        prompt_text_org = prompts_arr[i]\n        for model_id in models_json.keys():\n            model = models_json[ model_id ]\n            if( \"parameter_overrides\" in model ):\n                for parameter_name in model[\"parameter_overrides\"].keys():\n                    prompt_parameters[ parameter_name ] = model[\"parameter_overrides\"][ parameter_name ]\n            prompt_text = model[\"prompt_template\"] % ( prompt_text_org ) if ( \"prompt_template\" in model ) else prompt_text_org\n            raw_response, generated_output = generate( model_id, prompt_parameters, prompt_text, b_debug )\n            generated_output = generated_output.strip()\n            if( \"system\" in raw_response ):\n                del( raw_response[\"system\"] )\n            all_results_arr.append( { \"prompt_num\"       : i,\n                                      \"model_id\"         : model_id, \n                                      \"model_short_id\"   : re.sub( r\"^.*\\/\", \"\", model_id ),\n                                      \"prompt_text\"      : prompt_text,\n                                      \"raw_response\"     : raw_response, \n                                      \"generated_output\" : generated_output } )\n    return all_results_arr", "metadata": {"id": "68aeb5fe-5132-46f9-81b1-7d6539792501"}, "outputs": [], "execution_count": 92}, {"cell_type": "code", "source": "flan_template = \"\"\"I took my bird for a flight around the yard, it said *tweet*.\nI took my horse for a ride along the trail, it said *snort*.\nI took my fish for a swim in the lake, it said *bubbles*.\nI took my mouse for a cycle around the block, it said *squeak*.\nI took my cow for a drive to the mountains, it said *moo*.\nI took my donkey for a trek up the hill, it said *heehaw*.\n%s\"\"\"\n\ngranite_template = \"\"\"<|start_of_role|>system<|end_of_role|>\nContinue the given text.<|end_of_text|>\n<|start_of_role|>user<|end_of_role|>%s <|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>\"\"\"\n\nmodels_json = {\n    \"google/flan-t5-xxl\" : { \"prompt_template\" : flan_template },\n    \"ibm/granite-13b-instruct-v2\" : { \"parameter_overrides\" : { \"max_new_tokens\" : 60 }, \"prompt_template\" : granite_template },\n    \"meta-llama/llama-3-2-1b-instruct\" : { \"parameter_overrides\" : { \"max_new_tokens\" : 80, \"stop_sequences\" : [ \"\\n\" ] } }\n}", "metadata": {"id": "fe9227be-1c98-46c2-91ee-5fa33fec820f"}, "outputs": [], "execution_count": 107}, {"cell_type": "code", "source": "results_arr = promptModels4( prompts_arr, models_json, prompt_parameters )", "metadata": {"id": "7193e490-9c82-4148-acfb-da760d837a37"}, "outputs": [], "execution_count": 108}, {"cell_type": "code", "source": "g_prompt_col_width = \"440px\"\n\nresultsDF2( results_arr )", "metadata": {"id": "0fe91662-89fb-4fa4-8cc3-bfe83952d037"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "### Create a new display function to view generated output only", "metadata": {}}, {"cell_type": "code", "source": "def styleOutputCol( styler, col_names_arr ):\n    f_prompt = lambda v: \"width: 350px; \" + \\\n                         \"min-width: 350px; \" + \\\n                         \"max-width: 350px;\"\n    styler.applymap( f_prompt, subset=col_names_arr )\n    return styler\n\n\ndef resultsDF3( results_arr ):\n    \n    df_org = pd.DataFrame( results_arr )\n    result_df = df_org[ [ \"prompt_num\", \"model_short_id\", \"generated_output\" ] ]\n    result_df = result_df.sort_values( [ \"prompt_num\", \"model_short_id\" ] )\n    result_df = result_df.reset_index( drop=True )\n    result_df = result_df.replace( { \"\\\\n\" : \"<br/>\" }, regex=True )\n    \n    new_df = pd.DataFrame( columns=[ \"model_short_id\" ] )\n    prompt_nums_arr = sorted( result_df[ \"prompt_num\" ].unique() )\n    col_names_arr = []\n    for prompt_num in prompt_nums_arr:\n        col_name = \"output \" + str( prompt_num )\n        col_names_arr.append( col_name)\n        df_tmp = result_df[ result_df[\"prompt_num\"] == prompt_num ]\n        df_tmp = df_tmp.drop( \"prompt_num\", axis=1 )\n        df_tmp = df_tmp.rename( columns={ \"generated_output\": col_name } )\n        new_df = new_df.merge( df_tmp, how=\"right\", on=\"model_short_id\" )\n    \n    styler = new_df.style.pipe( styleDataFrame )\n    styler = styler.pipe( styleModelIDCol )\n    styler = styler.pipe( styleOutputCol, col_names_arr )\n        \n    return styler", "metadata": {"id": "372b5147-6432-4786-b09c-43e66e31eb02"}, "outputs": [], "execution_count": 110}, {"cell_type": "code", "source": "resultsDF3( results_arr )", "metadata": {"id": "d75f14bb-7615-459a-988c-b7393a85867c"}, "outputs": [{"execution_count": 111, "output_type": "execute_result", "data": {"text/plain": "<pandas.io.formats.style.Styler at 0x7f050ef6d7d0>", "text/html": "<style type=\"text/css\">\n#T_a8a47 th {\n  text-align: center;\n}\n#T_a8a47_row0_col0, #T_a8a47_row1_col0, #T_a8a47_row2_col0 {\n  text-align: left;\n  vertical-align: top;\n  padding: 10px 20px 10px 20px;\n  font-size: 120%;\n  width: 190px;\n  min-width: 190px;\n  max-width: 190px;\n}\n#T_a8a47_row0_col1, #T_a8a47_row0_col2, #T_a8a47_row1_col1, #T_a8a47_row1_col2, #T_a8a47_row2_col1, #T_a8a47_row2_col2 {\n  text-align: left;\n  vertical-align: top;\n  padding: 10px 20px 10px 20px;\n  font-size: 120%;\n  width: 350px;\n  min-width: 350px;\n  max-width: 350px;\n}\n</style>\n<table id=\"T_a8a47\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_a8a47_level0_col0\" class=\"col_heading level0 col0\" >model_short_id</th>\n      <th id=\"T_a8a47_level0_col1\" class=\"col_heading level0 col1\" >output 0</th>\n      <th id=\"T_a8a47_level0_col2\" class=\"col_heading level0 col2\" >output 1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_a8a47_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_a8a47_row0_col0\" class=\"data row0 col0\" >flan-t5-xxl</td>\n      <td id=\"T_a8a47_row0_col1\" class=\"data row0 col1\" >walk around the block, it said *woof*.</td>\n      <td id=\"T_a8a47_row0_col2\" class=\"data row0 col2\" >walk around the block, it said *meow*.</td>\n    </tr>\n    <tr>\n      <th id=\"T_a8a47_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_a8a47_row1_col0\" class=\"data row1 col0\" >granite-13b-instruct-v2</td>\n      <td id=\"T_a8a47_row1_col1\" class=\"data row1 col1\" >to the vet.</td>\n      <td id=\"T_a8a47_row1_col2\" class=\"data row1 col2\" >to the vet.</td>\n    </tr>\n    <tr>\n      <th id=\"T_a8a47_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_a8a47_row2_col0\" class=\"data row2 col0\" >llama-3-2-1b-instruct</td>\n      <td id=\"T_a8a47_row2_col1\" class=\"data row2 col1\" >30-minute walk around the block. I was looking forward to a relaxing afternoon, but as I was walking, I noticed that my dog was acting strangely. He was panting heavily and seemed to be getting more and more agitated by the minute.</td>\n      <td id=\"T_a8a47_row2_col2\" class=\"data row2 col2\" >30-minute walk around the block. I was excited to see how much she would enjoy the fresh air and exercise. As we strolled, I noticed that she was sniffing around a few bushes and then suddenly darted off towards a nearby alleyway.</td>\n    </tr>\n  </tbody>\n</table>\n"}, "metadata": {}}], "execution_count": 111}, {"cell_type": "code", "source": "", "metadata": {"id": "9ce04aaa-1641-4d32-97ae-3db1f16be479"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "5c777ad6-375b-490f-b4a8-84d00731e550"}, "outputs": [], "execution_count": null}]}